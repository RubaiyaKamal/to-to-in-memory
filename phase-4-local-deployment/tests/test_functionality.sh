#!/bin/bash

################################################################################
# Application Functionality Test Script
# Task 7.2: Create Application Functionality Test
# Reference: specs/003-local-k8s-deployment/tasks.md
#
# This script tests the functional correctness of the Todo Chatbot application
# deployed on Kubernetes, including:
# - CRUD operations (Create, Read, Update, Delete tasks)
# - Chatbot endpoint functionality
# - Data persistence after pod restarts
# - API error handling
#
# Prerequisites:
#   - Application must be deployed to Kubernetes
#   - kubectl configured with access to the cluster
#   - Namespace with deployed application exists
#
# Usage:
#   ./phase-4-local-deployment/tests/test_functionality.sh [OPTIONS]
#
# Options:
#   --namespace <name>              Kubernetes namespace (default: todo-chatbot)
#   --verbose                       Enable verbose output
#   --skip-restart                  Skip pod restart test
#   --help                          Show this help message
#
# Exit Codes:
#   0 - All tests passed
#   1 - One or more tests failed
#   2 - Prerequisites not met
################################################################################

set -euo pipefail

#------------------------------------------------------------------------------
# Configuration
#------------------------------------------------------------------------------

NAMESPACE="${NAMESPACE:-todo-chatbot}"
VERBOSE="${VERBOSE:-false}"
SKIP_RESTART="${SKIP_RESTART:-false}"

# Test results tracking
TESTS_PASSED=0
TESTS_FAILED=0
TESTS_TOTAL=0

# Temporary data for cleanup
CREATED_TASK_IDS=()

#------------------------------------------------------------------------------
# Color Output
#------------------------------------------------------------------------------

if [[ -t 1 ]]; then
    RED='\033[0;31m'
    GREEN='\033[0;32m'
    YELLOW='\033[1;33m'
    BLUE='\033[0;34m'
    MAGENTA='\033[0;35m'
    CYAN='\033[0;36m'
    NC='\033[0m'
else
    RED=''
    GREEN=''
    YELLOW=''
    BLUE=''
    MAGENTA=''
    CYAN=''
    NC=''
fi

#------------------------------------------------------------------------------
# Logging Functions
#------------------------------------------------------------------------------

log_info() {
    echo -e "${BLUE}[INFO]${NC} $*"
}

log_success() {
    echo -e "${GREEN}[SUCCESS]${NC} $*"
}

log_warning() {
    echo -e "${YELLOW}[WARNING]${NC} $*"
}

log_error() {
    echo -e "${RED}[ERROR]${NC} $*"
}

log_test() {
    echo -e "${MAGENTA}[TEST]${NC} $*"
}

log_verbose() {
    if [[ "${VERBOSE}" == "true" ]]; then
        echo -e "${CYAN}[VERBOSE]${NC} $*"
    fi
}

#------------------------------------------------------------------------------
# Test Result Functions
#------------------------------------------------------------------------------

test_pass() {
    local test_name="$1"
    ((TESTS_PASSED++))
    ((TESTS_TOTAL++))
    log_success "âœ“ ${test_name}"
}

test_fail() {
    local test_name="$1"
    local reason="${2:-Unknown failure}"
    ((TESTS_FAILED++))
    ((TESTS_TOTAL++))
    log_error "âœ— ${test_name}: ${reason}"
}

print_test_summary() {
    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${MAGENTA}TEST SUMMARY${NC}"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "Total Tests:  ${TESTS_TOTAL}"
    echo -e "Passed:       ${GREEN}${TESTS_PASSED}${NC}"
    echo -e "Failed:       ${RED}${TESTS_FAILED}${NC}"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"

    if [[ ${TESTS_FAILED} -eq 0 ]]; then
        log_success "All functionality tests passed! ğŸ‰"
        return 0
    else
        log_error "Some tests failed. Please review the output above."
        return 1
    fi
}

#------------------------------------------------------------------------------
# Help Function
#------------------------------------------------------------------------------

show_help() {
    cat << EOF
Application Functionality Test Script

Usage: $0 [OPTIONS]

Options:
    --namespace <name>              Kubernetes namespace (default: todo-chatbot)
    --verbose                       Enable verbose output
    --skip-restart                  Skip pod restart test
    --help                          Show this help message

Examples:
    # Run all functionality tests
    $0

    # Test specific namespace
    $0 --namespace my-namespace

    # Skip pod restart test (faster)
    $0 --skip-restart

    # Verbose output
    $0 --verbose

Exit Codes:
    0 - All tests passed
    1 - One or more tests failed
    2 - Prerequisites not met
EOF
}

#------------------------------------------------------------------------------
# Parse Arguments
#------------------------------------------------------------------------------

while [[ $# -gt 0 ]]; do
    case $1 in
        --namespace)
            NAMESPACE="$2"
            shift 2
            ;;
        --verbose)
            VERBOSE="true"
            shift
            ;;
        --skip-restart)
            SKIP_RESTART="true"
            shift
            ;;
        --help)
            show_help
            exit 0
            ;;
        *)
            log_error "Unknown option: $1"
            show_help
            exit 2
            ;;
    esac
done

#------------------------------------------------------------------------------
# Prerequisite Checks
#------------------------------------------------------------------------------

check_prerequisites() {
    log_info "Checking prerequisites..."

    local prereqs_ok=true

    # Check kubectl
    if ! command -v kubectl &> /dev/null; then
        log_error "kubectl is not installed or not in PATH"
        prereqs_ok=false
    fi

    # Check jq for JSON parsing
    if ! command -v jq &> /dev/null; then
        log_warning "jq is not installed (JSON parsing will be limited)"
        log_info "Install jq for better test output: apt-get install jq / brew install jq"
    fi

    # Check namespace exists
    if ! kubectl get namespace "${NAMESPACE}" &> /dev/null; then
        log_error "Namespace ${NAMESPACE} does not exist"
        log_info "Deploy the application first or specify correct namespace with --namespace"
        prereqs_ok=false
    fi

    # Check backend pod exists
    local backend_pod
    backend_pod=$(kubectl get pods -n "${NAMESPACE}" -l app=todo-chatbot-backend --no-headers 2>/dev/null | head -n1 | awk '{print $1}')

    if [[ -z "${backend_pod}" ]]; then
        log_error "No backend pod found in namespace ${NAMESPACE}"
        prereqs_ok=false
    else
        log_verbose "Backend pod found: ${backend_pod}"
    fi

    if [[ "${prereqs_ok}" == "false" ]]; then
        log_error "Prerequisites check failed"
        return 2
    fi

    log_success "All prerequisites met"
    return 0
}

#------------------------------------------------------------------------------
# Helper: Get Backend Pod
#------------------------------------------------------------------------------

get_backend_pod() {
    kubectl get pods -n "${NAMESPACE}" -l app=todo-chatbot-backend --no-headers 2>/dev/null | \
        grep Running | head -n1 | awk '{print $1}'
}

#------------------------------------------------------------------------------
# Helper: API Request
#------------------------------------------------------------------------------

api_request() {
    local method="$1"
    local endpoint="$2"
    local data="${3:-}"

    local backend_pod
    backend_pod=$(get_backend_pod)

    if [[ -z "${backend_pod}" ]]; then
        log_error "No running backend pod found"
        return 1
    fi

    local curl_cmd="curl -sf -X ${method} http://localhost:8001${endpoint}"

    if [[ -n "${data}" ]]; then
        curl_cmd="${curl_cmd} -H 'Content-Type: application/json' -d '${data}'"
    fi

    log_verbose "API Request: ${method} ${endpoint}"
    log_verbose "Pod: ${backend_pod}"

    local response
    response=$(kubectl exec -n "${NAMESPACE}" "${backend_pod}" -- \
        sh -c "${curl_cmd}" 2>/dev/null || echo "API_ERROR")

    echo "${response}"
}

#------------------------------------------------------------------------------
# Test 1: Create Task (POST)
#------------------------------------------------------------------------------

test_create_task() {
    log_test "Test 1: Create Task (POST /api/tasks)"

    local task_json='{"title":"Functionality Test Task","description":"Created by test script","completed":false}'

    log_verbose "Creating task with data: ${task_json}"

    local response
    response=$(api_request "POST" "/api/tasks" "${task_json}")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "Create Task" "API request failed"
        return 1
    fi

    log_verbose "Response: ${response}"

    # Extract task ID if jq is available
    if command -v jq &> /dev/null; then
        local task_id
        task_id=$(echo "${response}" | jq -r '.id' 2>/dev/null || echo "")

        if [[ -n "${task_id}" && "${task_id}" != "null" ]]; then
            CREATED_TASK_IDS+=("${task_id}")
            log_verbose "Task created with ID: ${task_id}"
            test_pass "Create Task (ID: ${task_id})"
            echo "${task_id}" > /tmp/test_task_id
            return 0
        else
            test_fail "Create Task" "Could not extract task ID from response"
            return 1
        fi
    else
        # Without jq, check if response contains expected fields
        if echo "${response}" | grep -q "Functionality Test Task"; then
            log_verbose "Task created (ID extraction skipped - jq not available)"
            test_pass "Create Task (verified by title)"
            return 0
        else
            test_fail "Create Task" "Response does not contain expected data"
            return 1
        fi
    fi
}

#------------------------------------------------------------------------------
# Test 2: Read All Tasks (GET)
#------------------------------------------------------------------------------

test_read_all_tasks() {
    log_test "Test 2: Read All Tasks (GET /api/tasks)"

    log_verbose "Fetching all tasks..."

    local response
    response=$(api_request "GET" "/api/tasks")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "Read All Tasks" "API request failed"
        return 1
    fi

    log_verbose "Response: ${response}"

    # Check if response contains our test task
    if echo "${response}" | grep -q "Functionality Test Task"; then
        log_verbose "Test task found in response"
        test_pass "Read All Tasks"
        return 0
    else
        test_fail "Read All Tasks" "Test task not found in response"
        return 1
    fi
}

#------------------------------------------------------------------------------
# Test 3: Read Single Task (GET by ID)
#------------------------------------------------------------------------------

test_read_single_task() {
    log_test "Test 3: Read Single Task (GET /api/tasks/{id})"

    local task_id
    if [[ -f /tmp/test_task_id ]]; then
        task_id=$(cat /tmp/test_task_id)
    else
        log_warning "Task ID not available, skipping single task read test"
        test_pass "Read Single Task (skipped - no ID)"
        return 0
    fi

    log_verbose "Fetching task ID: ${task_id}"

    local response
    response=$(api_request "GET" "/api/tasks/${task_id}")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "Read Single Task" "API request failed"
        return 1
    fi

    log_verbose "Response: ${response}"

    if echo "${response}" | grep -q "Functionality Test Task"; then
        log_verbose "Task retrieved successfully"
        test_pass "Read Single Task (ID: ${task_id})"
        return 0
    else
        test_fail "Read Single Task" "Task not found or incorrect data"
        return 1
    fi
}

#------------------------------------------------------------------------------
# Test 4: Update Task (PUT)
#------------------------------------------------------------------------------

test_update_task() {
    log_test "Test 4: Update Task (PUT /api/tasks/{id})"

    local task_id
    if [[ -f /tmp/test_task_id ]]; then
        task_id=$(cat /tmp/test_task_id)
    else
        log_warning "Task ID not available, skipping update test"
        test_pass "Update Task (skipped - no ID)"
        return 0
    fi

    local update_json='{"title":"Updated Functionality Test","description":"Modified by test script","completed":true}'

    log_verbose "Updating task ID ${task_id} with data: ${update_json}"

    local response
    response=$(api_request "PUT" "/api/tasks/${task_id}" "${update_json}")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "Update Task" "API request failed"
        return 1
    fi

    log_verbose "Response: ${response}"

    # Verify update by reading the task
    local verify_response
    verify_response=$(api_request "GET" "/api/tasks/${task_id}")

    if echo "${verify_response}" | grep -q "Updated Functionality Test"; then
        log_verbose "Task updated successfully"
        test_pass "Update Task (ID: ${task_id})"
        return 0
    else
        test_fail "Update Task" "Update not reflected in subsequent GET"
        return 1
    fi
}

#------------------------------------------------------------------------------
# Test 5: Chatbot Endpoint
#------------------------------------------------------------------------------

test_chatbot_endpoint() {
    log_test "Test 5: Chatbot Endpoint (POST /api/chat)"

    local chat_json='{"message":"List all my tasks","conversation_id":"test-conversation"}'

    log_verbose "Sending chatbot request: ${chat_json}"

    local response
    response=$(api_request "POST" "/api/chat" "${chat_json}")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "Chatbot Endpoint" "API request failed"
        return 1
    fi

    log_verbose "Response: ${response}"

    # Check if response contains expected structure
    if echo "${response}" | grep -q "response"; then
        log_verbose "Chatbot responded successfully"
        test_pass "Chatbot Endpoint"
        return 0
    else
        test_fail "Chatbot Endpoint" "Response does not contain expected structure"
        return 1
    fi
}

#------------------------------------------------------------------------------
# Test 6: Delete Task (DELETE)
#------------------------------------------------------------------------------

test_delete_task() {
    log_test "Test 6: Delete Task (DELETE /api/tasks/{id})"

    local task_id
    if [[ -f /tmp/test_task_id ]]; then
        task_id=$(cat /tmp/test_task_id)
    else
        log_warning "Task ID not available, skipping delete test"
        test_pass "Delete Task (skipped - no ID)"
        return 0
    fi

    log_verbose "Deleting task ID: ${task_id}"

    local response
    response=$(api_request "DELETE" "/api/tasks/${task_id}")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "Delete Task" "API request failed"
        return 1
    fi

    log_verbose "Response: ${response}"

    # Verify deletion by trying to read the task (should fail/return 404)
    local verify_response
    verify_response=$(api_request "GET" "/api/tasks/${task_id}" || echo "NOT_FOUND")

    if [[ "${verify_response}" == "NOT_FOUND" ]] || echo "${verify_response}" | grep -q "not found"; then
        log_verbose "Task deleted successfully"
        test_pass "Delete Task (ID: ${task_id})"
        rm -f /tmp/test_task_id
        return 0
    else
        test_fail "Delete Task" "Task still exists after deletion"
        return 1
    fi
}

#------------------------------------------------------------------------------
# Test 7: Data Persistence After Pod Restart
#------------------------------------------------------------------------------

test_data_persistence_restart() {
    log_test "Test 7: Data Persistence After Pod Restart"

    if [[ "${SKIP_RESTART}" == "true" ]]; then
        log_info "Skipping pod restart test (--skip-restart flag)"
        test_pass "Data Persistence After Restart (skipped)"
        return 0
    fi

    # Create a persistence test task
    local persist_json='{"title":"Persistence Test Task","description":"Should survive pod restart","completed":false}'

    log_info "Creating persistence test task..."

    local create_response
    create_response=$(api_request "POST" "/api/tasks" "${persist_json}")

    if [[ "${create_response}" == "API_ERROR" ]]; then
        test_fail "Data Persistence After Restart" "Failed to create test task"
        return 1
    fi

    local persist_task_id
    if command -v jq &> /dev/null; then
        persist_task_id=$(echo "${create_response}" | jq -r '.id' 2>/dev/null || echo "")
    fi

    # Get current backend pod
    local backend_pod
    backend_pod=$(get_backend_pod)

    if [[ -z "${backend_pod}" ]]; then
        test_fail "Data Persistence After Restart" "No backend pod found"
        return 1
    fi

    log_info "Deleting backend pod: ${backend_pod}"

    # Delete the pod
    if ! kubectl delete pod "${backend_pod}" -n "${NAMESPACE}" &> /dev/null; then
        test_fail "Data Persistence After Restart" "Failed to delete pod"
        return 1
    fi

    log_info "Waiting for new pod to be ready..."

    # Wait for new pod
    local timeout=60
    local elapsed=0

    while true; do
        local new_pod
        new_pod=$(get_backend_pod)

        if [[ -n "${new_pod}" && "${new_pod}" != "${backend_pod}" ]]; then
            log_verbose "New pod is ready: ${new_pod}"
            break
        fi

        if [[ ${elapsed} -ge ${timeout} ]]; then
            test_fail "Data Persistence After Restart" "New pod not ready after ${timeout}s"
            return 1
        fi

        sleep 2
        ((elapsed += 2))
    done

    # Wait additional time for pod to be fully ready
    sleep 5

    log_info "Verifying task persistence after restart..."

    # Check if the persistence test task still exists
    local verify_response
    verify_response=$(api_request "GET" "/api/tasks")

    if [[ "${verify_response}" == "API_ERROR" ]]; then
        test_fail "Data Persistence After Restart" "Failed to retrieve tasks after restart"
        return 1
    fi

    if echo "${verify_response}" | grep -q "Persistence Test Task"; then
        log_success "Task survived pod restart"

        # Clean up the persistence test task
        if [[ -n "${persist_task_id}" && "${persist_task_id}" != "null" ]]; then
            log_verbose "Cleaning up persistence test task (ID: ${persist_task_id})"
            api_request "DELETE" "/api/tasks/${persist_task_id}" &> /dev/null || true
        fi

        test_pass "Data Persistence After Restart"
        return 0
    else
        test_fail "Data Persistence After Restart" "Task not found after pod restart"
        return 1
    fi
}

#------------------------------------------------------------------------------
# Test 8: API Error Handling
#------------------------------------------------------------------------------

test_api_error_handling() {
    log_test "Test 8: API Error Handling"

    log_info "Testing error response for non-existent task..."

    # Try to get a task with invalid ID
    local response
    response=$(api_request "GET" "/api/tasks/99999" || echo "ERROR_HANDLED")

    if [[ "${response}" == "API_ERROR" ]]; then
        test_fail "API Error Handling" "API request failed unexpectedly"
        return 1
    fi

    log_verbose "Response: ${response}"

    # Check if error is properly handled (should return 404 or error message)
    if [[ "${response}" == "ERROR_HANDLED" ]] || echo "${response}" | grep -qi "not found"; then
        log_verbose "API properly handles non-existent resource"
        test_pass "API Error Handling"
        return 0
    else
        log_warning "API error handling could not be verified"
        test_pass "API Error Handling (partial verification)"
        return 0
    fi
}

#------------------------------------------------------------------------------
# Cleanup
#------------------------------------------------------------------------------

cleanup_test_data() {
    log_info "Cleaning up test data..."

    # Clean up any remaining test tasks
    if [[ -f /tmp/test_task_id ]]; then
        local task_id
        task_id=$(cat /tmp/test_task_id)

        log_verbose "Cleaning up task ID: ${task_id}"
        api_request "DELETE" "/api/tasks/${task_id}" &> /dev/null || true

        rm -f /tmp/test_task_id
    fi

    log_verbose "Cleanup complete"
}

#------------------------------------------------------------------------------
# Main Test Execution
#------------------------------------------------------------------------------

main() {
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${MAGENTA}Todo Chatbot - Application Functionality Test${NC}"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""
    echo "Configuration:"
    echo "  Namespace:       ${NAMESPACE}"
    echo "  Skip Restart:    ${SKIP_RESTART}"
    echo "  Verbose:         ${VERBOSE}"
    echo ""

    # Check prerequisites
    if ! check_prerequisites; then
        log_error "Prerequisites check failed"
        exit 2
    fi

    echo ""
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo -e "${MAGENTA}Running Functionality Tests${NC}"
    echo "â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    echo ""

    # Run all tests
    test_create_task
    test_read_all_tasks
    test_read_single_task
    test_update_task
    test_chatbot_endpoint
    test_delete_task
    test_data_persistence_restart
    test_api_error_handling

    # Cleanup
    cleanup_test_data

    # Print summary
    echo ""
    if print_test_summary; then
        exit 0
    else
        exit 1
    fi
}

# Run main function
main "$@"
